{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset folder organize\n",
    "\n",
    "### X_Dataset Split bird_call, background\n",
    "\n",
    "total : 20000  \n",
    "bird_call : 10017  \n",
    "background : 9983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRoot = \"C:/Users/CHAM/Desktop/2021_class/에너지환경통계/EES_project/dataset\"\n",
    "metaDF = pd.read_csv(dataRoot + '/BirdVoxDCASE20k_csvpublic.csv')\n",
    "\n",
    "for idx, row in metaDF.iterrows():\n",
    "    itemid = row['itemid']\n",
    "    src_path = f\"{dataRoot}/wav/{itemid}.wav\"\n",
    "    if row['hasbird'] == 1:\n",
    "        dist_path = f\"{dataRoot}/bird_call/{itemid}.wav\"\n",
    "    else:\n",
    "        dist_path = f\"{dataRoot}/background/{itemid}.wav\"\n",
    "        \n",
    "    shutil.move(src_path, dist_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_Dataset Split Train, Val\n",
    "\n",
    "train  \n",
    "bird_call : 8014   \n",
    "background : 7986\n",
    "\n",
    "val  \n",
    "bird_call : 2003  \n",
    "background : 1997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_call_list = glob(dataRoot + '/bird_call/*.wav')\n",
    "background_list = glob(dataRoot + '/background/*.wav')\n",
    "\n",
    "np.random.seed(len(bird_call_list))\n",
    "val_bird_call = np.random.choice(bird_call_list, round(len(bird_call_list)*0.2), replace=False)\n",
    "\n",
    "np.random.seed(len(background_list))\n",
    "val_background = np.random.choice(background_list, round(len(background_list)*0.2), replace=False)\n",
    "\n",
    "for file in val_bird_call:\n",
    "    fileName = os.path.basename(file)\n",
    "    shutil.move(file, dataRoot + '/val/bird_call/' + fileName)\n",
    "\n",
    "for file in val_background:\n",
    "    fileName = os.path.basename(file)\n",
    "    shutil.move(file, dataRoot + '/val/background/' + fileName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdVoxDataset(Dataset):\n",
    "    def __init__(self, config, split):\n",
    "        self.seg = config['seg']\n",
    "        self.categories = config['categories']\n",
    "        self.num_class = len(self.categories)\n",
    "        self.transforms = nn.Sequential(\n",
    "            T.Resample(config['origin_Fs'], config['Fs']),\n",
    "            T.MelSpectrogram(sample_rate=config['Fs'], n_fft=config['n_fft'], n_mels=config['n_mels'])\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.file_list = []\n",
    "        for category in self.categories:\n",
    "            self.file_list.extend(glob(f\"{config['data_root']}/{split}/{category}/*.wav\"))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        audio, sample_rate = torchaudio.load(self.file_list[index])\n",
    "        if len(audio) > 1:\n",
    "            audio = audio.mean(dim=0)                                       \n",
    "        audio = self.transforms(audio)\n",
    "\n",
    "        for i in range(self.num_class):\n",
    "            if self.categories[i] in self.file_list[index]:\n",
    "                label = i\n",
    "\n",
    "        return audio, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "input size: torch.Size([16, 1, 64, 313]), labels: torch.Size([16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # ============== Config Init ==============\n",
    "    config = {\n",
    "        \"dataset\" : \"BirdVox-DCASE-20k\",\n",
    "        \"data_root\" : \"C:/Users/CHAM/Desktop/2021_class/EES/EES_project/dataset\",\n",
    "        \"categories\" : [\"background\", \"bird_call\"],\n",
    "        \"seg\" : 1,\n",
    "        \"origin_Fs\" : 44100,\n",
    "        \"Fs\" : 16000,\n",
    "        \"n_fft\" : 1024,\n",
    "        \"n_mels\" : 64,\n",
    "        'model_name' : 'ResNet_attention',\n",
    "        'drop_rate' : 0.1,\n",
    "        'epochs': 50,\n",
    "        'h_test' : 5,\n",
    "        'batch_size': 16,\n",
    "        'learning_rate': 0.01,\n",
    "        'h_stepsize' : 2,\n",
    "        'h_decay' : 0.95,\n",
    "        'optimizer': 'sgd'\n",
    "        'device' : torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    }\n",
    "\n",
    "    #     wandb.init(config=config, project='EES_proejct', entity='jaekyeong')\n",
    "    #     wandb.run.name = config_defaults['model_name']\n",
    "\n",
    "\n",
    "    # ============== Data Load ==============\n",
    "    train_set = BirdVoxDataset(config, split='train')\n",
    "    train_loader = DataLoader(train_set, batch_size=config['batch_size'], num_workers=0, shuffle=True)\n",
    "\n",
    "    val_set = BirdVoxDataset(config, split='val')\n",
    "    test_loader = DataLoader(val_set, batch_size=config['batch_size'], num_workers=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size: torch.Size([16, 1, 64, 313]), labels: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== Model Init ==============\n",
    "    \n",
    "    model_config = {\n",
    "        # 'Simple_CNN' : models.CNN(config.num_classes).to(device)\n",
    "        # 'CNN_v2' : models.CNN_v2(config.num_classes).to(device),\n",
    "        # 'ResNet18' : models.resnet18().to(device),\n",
    "        # 'ResNet50' : models.resnet50().to(device),\n",
    "        # 'DenseNet201' : models.densenet201(drop_rate=float(config.drop_rate), num_classes=int(config.num_classes)).to(device),\n",
    "        'ResNet_attention' : models.ResidualNet(depth=101, num_classes=trainset.num_class, att_type='CBAM').to(device)      # att_type : CBAM or BAM\n",
    "    }\n",
    "    model = model_config[config.model_name]\n",
    "    model = nn.DataParallel(model)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "   # Define the optimizer\n",
    "    if config.optimizer=='sgd':\n",
    "      optim = torch.optim.SGD(model.parameters(),lr=config.learning_rate, momentum=0.9)\n",
    "    elif config.optimizer=='adam':\n",
    "      optim = torch.optim.Adam(model.parameters(),lr=config.learning_rate)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optim, config.h_stepsize, config.h_decay)\n",
    "\n",
    "    wandb.watch(model)\n",
    "\n",
    "    # ============== Train & Test ==============\n",
    "    best_labels, best_y_hat, best_acc = [], [], 0.\n",
    "    for epoch in range(config.epochs):\n",
    "        # ========> Train\n",
    "        model.train()\n",
    "\n",
    "        total_loss, running_loss = 0.0,  0.0\n",
    "        for batch_idx, data in enumerate(tqdm(train_loader, desc=f'{epoch + 1:2d}')):\n",
    "            optim.zero_grad()\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        # logging\n",
    "        wandb.log({\"Train Loss\" : total_loss, \"global_step\" : epoch+1})\n",
    "        print(f'[{(epoch+1):2d}/{config.epochs:4d}] loss: {total_loss:.6f}')\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        # ========> Test\n",
    "        total_loss = 0.0\n",
    "        if(epoch % config.h_test == config.h_test-1):\n",
    "            model.eval()\n",
    "            save_model(model_save_path, config.model_name, model, epoch)\n",
    "            \n",
    "            y_hat_total, labels_total, total_loss = [], [], 0.0\n",
    "            with torch.no_grad():\n",
    "                for i, data in enumerate(test_loader):\n",
    "                    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                    labels_total += labels.tolist()\n",
    "                    outputs = model(inputs)\n",
    "                    loss = loss_fn(outputs, labels)\n",
    "                    total_loss += loss.item()\n",
    "\n",
    "                    y_hat = torch.argmax(outputs, dim=1)\n",
    "                    y_hat_total += y_hat.tolist()\n",
    "                \n",
    "                acc = print_report(labels_total, y_hat_total, total_loss, testset.categories)\n",
    "       \n",
    "                # Best Accuracy Check\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                    best_labels = labels_total\n",
    "                    best_y_hat = y_hat_total\n",
    "        \n",
    "                wandb.log({\"Test Acc\": 100.*acc, \n",
    "                    \"Test Loss\": total_loss,\n",
    "                    \"learning_rate\": optim.param_groups[0]['lr'], \n",
    "                    \"global_step\" : epoch+1})\n",
    "            \n",
    "    wandb.log({\"conf_mat\" : wandb.sklearn.plot_confusion_matrix(best_labels, best_y_hat, testset.categories)})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ees]",
   "language": "python",
   "name": "conda-env-ees-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
